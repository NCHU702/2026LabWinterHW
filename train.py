import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import csv
from datetime import datetime

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
from config import CONFIG
from utils import find_typhoon_data, masked_mse_loss
from dataset import StochasticRainDataset
from model import HydroNetRainOnly

def init_weights(m):
    """åˆå§‹åŒ–æ¨¡å‹æ¬Šé‡"""
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')
        if m.bias is not None:
            nn.init.constant_(m.bias, 0)

def train():
    # è¨­ç½®éš¨æ©Ÿç¨®å­ä»¥ç¢ºä¿å¯é‡ç¾æ€§
    torch.manual_seed(42)
    np.random.seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(42)
    
    # 1. æº–å‚™è³‡æ–™
    print("æ­£åœ¨æœå°‹è¨“ç·´è³‡æ–™...")
    train_sequences = find_typhoon_data(CONFIG['train_data_dir'])
    
    print("æ­£åœ¨æœå°‹é©—è­‰è³‡æ–™...")
    val_sequences = find_typhoon_data('val_data')
    
    if len(train_sequences) == 0:
        print("æœªæ‰¾åˆ°è¨“ç·´è³‡æ–™ï¼Œè«‹æª¢æŸ¥è·¯å¾‘ã€‚")
        return
    
    if len(val_sequences) == 0:
        print("æœªæ‰¾åˆ°é©—è­‰è³‡æ–™ï¼Œè«‹æª¢æŸ¥è·¯å¾‘ã€‚")
        return
    
    # å»ºç«‹è¨“ç·´é›†å’Œé©—è­‰é›†
    train_ds = StochasticRainDataset(train_sequences, CONFIG)
    val_ds = StochasticRainDataset(val_sequences, CONFIG)
    
    train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=CONFIG['batch_size'], shuffle=False)
    
    print(f"Train samples: {len(train_ds)}, Val samples: {len(val_ds)}")
    
    # 2. åˆå§‹åŒ–æ¨¡å‹
    model = HydroNetRainOnly().to(CONFIG['device'])
    model.apply(init_weights)  # åˆå§‹åŒ–æ¬Šé‡
    
    optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])
    
    # å­¸ç¿’ç‡èª¿åº¦å™¨
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, 
        mode='min',
        factor=0.5,
        patience=5,
        verbose=True,
        min_lr=1e-6
    )
    
    # è¿½è¹¤æœ€ä½³æ¨¡å‹å’Œæ—©åœ
    best_val_loss = float('inf')
    patience = 10
    patience_counter = 0
    
    # å‰µå»ºè¨“ç·´æ—¥èªŒ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_path = os.path.join(CONFIG['save_dir'], f'training_log_{timestamp}.csv')
    log_file = open(log_path, 'w', newline='')
    log_writer = csv.writer(log_file)
    log_writer.writerow(['epoch', 'train_loss', 'val_loss', 'learning_rate', 'best_val_loss'])
    
    print(f"\né–‹å§‹è¨“ç·´... (æ—¥èªŒ: {log_path})")
    print("=" * 80)
    
    # 3. è¨“ç·´è¿´åœˆ
    for epoch in range(CONFIG['num_epochs']):
        # ===== è¨“ç·´éšæ®µ =====
        model.train()
        train_loss = 0
        
        for i, (inputs, targets, masks) in enumerate(train_loader):
            inputs = inputs.to(CONFIG['device'])
            targets = targets.to(CONFIG['device'])
            masks = masks.to(CONFIG['device'])
            
            optimizer.zero_grad()
            outputs = model(inputs)
            
            # ä½¿ç”¨ Utils ä¸­çš„é®ç½©æå¤±å‡½æ•¸
            loss = masked_mse_loss(outputs, targets, masks)
            
            loss.backward()
            
            # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            train_loss += loss.item()
            
            if i % 10 == 0:
                print(f"Epoch {epoch+1}/{CONFIG['num_epochs']} [Batch {i}/{len(train_loader)}] Loss: {loss.item():.6f}")
                
        avg_train_loss = train_loss / len(train_loader)
        
        # ===== é©—è­‰éšæ®µ =====
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for inputs, targets, masks in val_loader:
                inputs = inputs.to(CONFIG['device'])
                targets = targets.to(CONFIG['device'])
                masks = masks.to(CONFIG['device'])
                
                outputs = model(inputs)
                loss = masked_mse_loss(outputs, targets, masks)
                val_loss += loss.item()
        
        avg_val_loss = val_loss / len(val_loader)
        
        # æ›´æ–°å­¸ç¿’ç‡
        current_lr = optimizer.param_groups[0]['lr']
        scheduler.step(avg_val_loss)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹ä¸¦æª¢æŸ¥æ—©åœ
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            best_model_path = os.path.join(CONFIG['save_dir'], 'best_model.pth')
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': best_val_loss,
            }, best_model_path)
        else:
            patience_counter += 1
        
        # è¼¸å‡ºè¨“ç·´ä¿¡æ¯
        print("=" * 80)
        print(f"Epoch {epoch+1}/{CONFIG['num_epochs']} å®Œæˆ")
        print(f"  Train Loss: {avg_train_loss:.6f}")
        print(f"  Val Loss:   {avg_val_loss:.6f}")
        print(f"  LR:         {current_lr:.2e}")
        print(f"  Best Val:   {best_val_loss:.6f}")
        
        if avg_val_loss == best_val_loss:
            print(f"  ğŸŒŸ æ–°çš„æœ€ä½³æ¨¡å‹ï¼")
        else:
            print(f"  â³ æ²’æœ‰æ”¹å–„ ({patience_counter}/{patience})")
        
        # è¨˜éŒ„æ—¥èªŒ
        log_writer.writerow([epoch+1, avg_train_loss, avg_val_loss, current_lr, best_val_loss])
        log_file.flush()
        
        # æ¯ 5 å€‹ epoch å­˜æª”ä¸€æ¬¡
        if (epoch + 1) % 5 == 0:
            save_path = os.path.join(CONFIG['save_dir'], f'model_ep{epoch+1}.pth')
            torch.save(model.state_dict(), save_path)
            print(f"  ğŸ’¾ å·²ä¿å­˜æª¢æŸ¥é»: model_ep{epoch+1}.pth")
        
        # æª¢æŸ¥æ—©åœ
        if patience_counter >= patience:
            print(f"\nâš ï¸  Early Stopping at Epoch {epoch+1}")
            print(f"   æœ€ä½³ Val Loss: {best_val_loss:.6f}")
            break
        
        print("=" * 80)
    
    # é—œé–‰æ—¥èªŒæ–‡ä»¶
    log_file.close()
    
    print("\nâœ… è¨“ç·´å®Œæˆï¼")
    print(f"   æœ€çµ‚æœ€ä½³ Val Loss: {best_val_loss:.6f}")
    print(f"   è¨“ç·´æ—¥èªŒ: {log_path}")
    print(f"   æœ€ä½³æ¨¡å‹: {os.path.join(CONFIG['save_dir'], 'best_model.pth')}")

if __name__ == "__main__":
    train()
